{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcAKyld1WYiI"
      },
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kly3uBkQcUQ"
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGsA0btrWoSw"
      },
      "source": [
        "### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RwHQRFGFXXB2"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUp49BEMXfIt"
      },
      "source": [
        "###Set the API KEY using Google colab user data option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wGnsMFlwXJn3"
      },
      "outputs": [],
      "source": [
        "openai_access = userdata.get('open_ai')\n",
        "os.environ['OPENAI_API_KEY'] = openai_access\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOp8EptQYNva"
      },
      "source": [
        "### Read the configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BvkQ3z09YMmi"
      },
      "outputs": [],
      "source": [
        "json_file_path = \"/content/drive/MyDrive/Colab Notebooks/config.json\"\n",
        "with open(json_file_path, \"r\") as file:\n",
        "    configuration = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cejHIQDEZjVG"
      },
      "source": [
        "### Load the user story descriptions to data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FAF2qKiRPm_L"
      },
      "outputs": [],
      "source": [
        "input_csv_path = configuration['input_csv_path']\n",
        "# Read the complete CSV file as a pandas DataFrame\n",
        "data_frame = pd.read_csv(input_csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtu-AM87aVNn"
      },
      "source": [
        "## STEPS\n",
        "### 1.   Read each user story description\n",
        "### 2.   Set the model [gpt3.5-turbo, gpt-4] and model parameters\n",
        "### 3.   Read the zero, few-shot prompt from configuration\n",
        "### 4.   call OPEN AI chat completion end point\n",
        "### 5. save the response as .feature file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "WIVBA_b6diLk",
        "outputId": "10a198b2-8bcf-4ac4-bf75-4a22d3a79a72"
      },
      "outputs": [],
      "source": [
        "# Specify the columns to iterate\n",
        "#step 1\n",
        "us_desc_column=configuration['us_desc_column']\n",
        "app_desc_column=configuration['app_desc_column']\n",
        "# read model, configuration parameters\n",
        "#step 2\n",
        "gpt_3_model=configuration['gpt_3.5_model']\n",
        "gpt_4_model=configuration['gpt_4_model']\n",
        "gpt_temperature=configuration['gpt_temperature']\n",
        "gpt_top_p=configuration['gpt_top_p']\n",
        "gpt_max_tokens=configuration['gpt_max_tokens']\n",
        "response_file_name_gpt_3=configuration['response_feature_file_gpt_3.5']\n",
        "response_file_name_gpt_4=configuration['response_feature_file_gpt_4']\n",
        "few_shot_method=configuration['few_shot_method']\n",
        "zero_shot_method=configuration['zero_shot_method']\n",
        "output_csv_path=configuration['output_csv_path']\n",
        "#step 3\n",
        "system_prompt=configuration['system_prompt']\n",
        "openaiclient = OpenAI()\n",
        "# Iterate over each row to read user story descriptions\n",
        "for index, row in data_frame.iterrows():\n",
        "    user_story = row[us_desc_column]\n",
        "    story_context = row[app_desc_column]\n",
        "    #step 3\n",
        "    zero_shot_array=configuration['zero_shot']\n",
        "    zero_shot=' '.join(zero_shot_array)\n",
        "    few_shot_user_prompt_array=configuration['few_shot_user_prompt']\n",
        "    few_shot_user_prompt=' '.join(few_shot_user_prompt_array)\n",
        "    few_shot_assistant_prompt_array=configuration['few_shot_assistant_prompt']\n",
        "    few_shot_assistant_prompt=' '.join(few_shot_assistant_prompt_array)\n",
        "    user_message =   zero_shot+user_story\n",
        "    #call the openai api for generating feature file by proving zero or few shot prompts\n",
        "    #step 4\n",
        "    chat_suggestion = openaiclient.chat.completions.create(\n",
        "    messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": few_shot_user_prompt},\n",
        "                {\"role\":\"assistant\",\"content\": few_shot_assistant_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_message},\n",
        "            ],\n",
        "            #model=gpt_4_model,\n",
        "            model=gpt_3_model,\n",
        "            temperature=gpt_temperature,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            top_p=gpt_top_p,\n",
        "           # max_tokens=gpt_max_tokens,\n",
        "            #seed=1\n",
        "        )\n",
        "\n",
        "    # get the response\n",
        "    output_response = chat_suggestion.choices[0].message.content\n",
        "    # create date timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    response_file_name = f\"US{index}_{timestamp}_{few_shot_method}_{response_file_name_gpt_3}.feature\"\n",
        "    # Write the response to a feature file\n",
        "    # step 5\n",
        "    feature_file_path = output_csv_path+response_file_name\n",
        "    with open(feature_file_path, 'w', encoding='utf-8') as feature_file:\n",
        "      feature_file.write(output_response)\n",
        "      time.sleep(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
