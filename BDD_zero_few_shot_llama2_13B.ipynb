{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install required packages"
      ],
      "metadata": {
        "id": "sENK5v0C4d_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEaEabrkbCRo"
      },
      "outputs": [],
      "source": [
        "!pip install replicate\n",
        "#Documentation -https://replicate.com/meta/llama-2-70b/api?tab=python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required libraries"
      ],
      "metadata": {
        "id": "pas96-5w4myi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import replicate\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "import json"
      ],
      "metadata": {
        "id": "zLV0WbNrbPQm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the API KEY using Google colab user data option"
      ],
      "metadata": {
        "id": "I21LL_Iz5axj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replicate_access = userdata.get('replicate')\n",
        "os.environ['REPLICATE_API_KEY'] = replicate_access"
      ],
      "metadata": {
        "id": "g7nrv0Po5dL7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the configurations"
      ],
      "metadata": {
        "id": "y3EdPKP75uHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_path = \"/content/drive/MyDrive/Colab Notebooks/config.json\"\n",
        "with open(json_file_path, \"r\") as file:\n",
        "    configuration = json.load(file)"
      ],
      "metadata": {
        "id": "rcDhdAPx59rw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the user story descriptions to data frame"
      ],
      "metadata": {
        "id": "Jaio6aQo6fVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_csv_path = configuration['input_csv_path']\n",
        "# Read the complete CSV file as a pandas DataFrame\n",
        "data_frame = pd.read_csv(input_csv_path)"
      ],
      "metadata": {
        "id": "lHfHM8V06jGz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEPS\n",
        "### 1.   Read each user story description\n",
        "### 2.   Set the model [llama2-13B] and model parameters\n",
        "### 3.   Read the zero, few-shot prompt from configuration\n",
        "### 4.   Call replica chat completion end point\n",
        "### 5. Save the response as .feature file"
      ],
      "metadata": {
        "id": "so4pkIDg6lK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the columns to iterate\n",
        "#step 1\n",
        "us_desc_column=configuration['us_desc_column']\n",
        "app_desc_column=configuration['app_desc_column']\n",
        "# read model, configuration parameters\n",
        "#step 2\n",
        "llama2_model=configuration['llama2_model']\n",
        "llama2_temperature=configuration['llama2_temperature']\n",
        "llama2_top_p=configuration['llama2_top_p']\n",
        "llama2_max_tokens=configuration['llama2_max_tokens']\n",
        "response_feature_file_llama2=configuration['response_feature_file_llama2']\n",
        "few_shot_method=configuration['few_shot_method']\n",
        "zero_shot_method=configuration['zero_shot_method']\n",
        "output_csv_path=configuration['output_csv_path']\n",
        "#step 3\n",
        "system_prompt=configuration['system_prompt']\n",
        "# Iterate over each row to read user story descriptions\n",
        "for index, row in data_frame.iterrows():\n",
        "    user_story = row[us_desc_column]\n",
        "    story_context = row[app_desc_column]\n",
        "    #step 3\n",
        "    zero_shot_array=configuration['zero_shot']\n",
        "    zero_shot=' '.join(zero_shot_array)\n",
        "    few_shot_user_prompt_array=configuration['few_shot_user_prompt']\n",
        "    few_shot_user_prompt=' '.join(few_shot_user_prompt_array)\n",
        "    few_shot_assistant_prompt_array=configuration['few_shot_assistant_prompt']\n",
        "    few_shot_assistant_prompt=' '.join(few_shot_assistant_prompt_array)\n",
        "    user_message = zero_shot+user_story\n",
        "    api = replicate.Client(api_token=os.environ['REPLICATE_API_KEY'])\n",
        "    prompt = f\"{system_prompt}\\n{few_shot_user_prompt}\\n{few_shot_assistant_prompt}\\n{user_message}\"\n",
        "    # step 4\n",
        "    output = api.run(\n",
        "        \"meta/llama-2-13b-chat\",\n",
        "       #\"meta/llama-2-7b-chat\",\n",
        "       # input={\"prompt\": user_message,\n",
        "         input={\n",
        "                 \"prompt\":prompt,\n",
        "                 \"temperature\": llama2_temperature,\n",
        "                 \"max_new_tokens\": llama2_max_tokens,\n",
        "                 \"top_p\":llama2_top_p,\n",
        "               }\n",
        "        )\n",
        "    output_text=''\n",
        "    output_text = ''.join(output)\n",
        "    time.sleep(20)\n",
        "    # Specify the output file name\n",
        "    #step 5s\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_file_name = f\"US{index}_{timestamp}_{few_shot_method}_{response_feature_file_llama2}.feature\"\n",
        "        # Specify the path where you want to save the output file\n",
        "    output_file_path = os.path.join(output_csv_path, output_file_name)\n",
        "    # Write the output texts to a text file\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(output_text)"
      ],
      "metadata": {
        "id": "WAfmAunL679V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}